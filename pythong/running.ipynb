{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:51:16.956594Z",
     "start_time": "2024-11-30T17:50:25.723951Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Define the file path to the train.tsv file\n",
    "file_path = r\"C:\\projects\\lauzhack-2024\\liar_dataset-master\\train.tsv\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "model_name = \"jy46604790/Fake-News-Bert-Detect\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Load the LIAR dataset (train.tsv) into a Pandas DataFrame\n",
    "columns = ['id', 'label', 'statement', 'subject', 'speaker', 'speaker_job_title',\n",
    "           'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts',\n",
    "           'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context']\n",
    "liar_data = pd.read_csv(file_path, sep='\\t', header=None, names=columns)\n",
    "\n",
    "# Extract 100 samples for verification\n",
    "sample_data = liar_data.head(333)\n",
    "\n",
    "# Preprocess the statements\n",
    "def preprocess_statements(statements, tokenizer, max_length=128):\n",
    "    encodings = tokenizer(statements, truncation=True, padding=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    return encodings\n",
    "\n",
    "# Prepare input data\n",
    "statements = sample_data['statement'].tolist()\n",
    "encodings = preprocess_statements(statements, tokenizer)\n",
    "\n",
    "# Perform inference with the model\n",
    "def get_predictions(model, encodings):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encodings)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=1)  # Convert logits to probabilities\n",
    "        predictions = torch.argmax(probabilities, dim=1)  # Get predicted class\n",
    "    return predictions, probabilities\n",
    "\n",
    "predictions, probabilities = get_predictions(model, encodings)\n",
    "\n",
    "# Display the results (no NumPy)\n",
    "results = pd.DataFrame({\n",
    "    'Statement': statements,\n",
    "    'Predicted_Label': [pred.item() for pred in predictions],  # Convert each tensor item to a regular Python value\n",
    "    'Probabilities': [prob.tolist() for prob in probabilities]  # Convert each tensor to a list\n",
    "})\n",
    "print(results)\n",
    "\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.14k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67433ff22e0b413bb75d2cdeaaf23e08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddf247d5a16143c894e4eb878df3af77"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20c243f9aa3b48219e2806b108875d3c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f99688f459924014b04f6dcaebe006ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7baa4dfb2f4547039816c3c72ec823f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e65336ccbcc415e8537455b38081c3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Statement  Predicted_Label  \\\n",
      "0    Says the Annies List political group supports ...                0   \n",
      "1    When did the decline of coal start? It started...                0   \n",
      "2    Hillary Clinton agrees with John McCain \"by vo...                0   \n",
      "3    Health care reform legislation is likely to ma...                0   \n",
      "4    The economic turnaround started at the end of ...                0   \n",
      "..                                                 ...              ...   \n",
      "328  Over 40 percent of small and mid-size banks th...                0   \n",
      "329  You cant check out a library book without a ph...                0   \n",
      "330  Says that Starbucks took Christmas off of thei...                0   \n",
      "331  Atmospheric conditions could push a footballs ...                0   \n",
      "332  Hillary Clinton supports unlimited abortion on...                0   \n",
      "\n",
      "                                   Probabilities  \n",
      "0     [0.9976226687431335, 0.002377317054197192]  \n",
      "1    [0.9990242719650269, 0.0009757785010151565]  \n",
      "2     [0.9860281944274902, 0.013971861451864243]  \n",
      "3    [0.9967053532600403, 0.0032946544233709574]  \n",
      "4      [0.993440568447113, 0.006559500005096197]  \n",
      "..                                           ...  \n",
      "328    [0.7823565006256104, 0.21764346957206726]  \n",
      "329   [0.998823344707489, 0.0011766876559704542]  \n",
      "330  [0.9994194507598877, 0.0005805320106446743]  \n",
      "331   [0.9953773021697998, 0.004622700624167919]  \n",
      "332  [0.9980731010437012, 0.0019269217737019062]  \n",
      "\n",
      "[333 rows x 3 columns]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-30T17:53:21.747052Z",
     "start_time": "2024-11-30T17:53:21.699668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert predictions to a Python list and match with the actual labels\n",
    "true_labels = sample_data['label'].tolist()\n",
    "\n",
    "# Map string labels to numerical values (if necessary, depending on model's output format)\n",
    "# Example: You may need to map the labels if your model outputs class indices like 0, 1, 2...\n",
    "label_mapping = {\n",
    "    'true': 1,\n",
    "    'mostly-true': 1,\n",
    "    'half-true': 0,\n",
    "    'barely-true': 0,\n",
    "    'false': 0,\n",
    "    'pants-fire': 0\n",
    "}\n",
    "\n",
    "# Map true labels to numerical format (for comparison with model's predictions)\n",
    "true_labels_numeric = [label_mapping[label] for label in true_labels]\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = sum([pred == true for pred, true in zip(predictions, true_labels_numeric)])\n",
    "accuracy = correct_predictions / len(true_labels_numeric)\n",
    "\n",
    "# Display the results\n",
    "results = pd.DataFrame({\n",
    "    'Statement': statements,\n",
    "    'True_Label': true_labels,\n",
    "    'Predicted_Label': [pred.item() for pred in predictions],  # Convert each tensor item to a regular Python value\n",
    "    'Probabilities': [prob.tolist() for prob in probabilities]  # Convert each tensor to a list\n",
    "})\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(results)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: tensor(0.6186)\n",
      "                                             Statement   True_Label  \\\n",
      "0    Says the Annies List political group supports ...        false   \n",
      "1    When did the decline of coal start? It started...    half-true   \n",
      "2    Hillary Clinton agrees with John McCain \"by vo...  mostly-true   \n",
      "3    Health care reform legislation is likely to ma...        false   \n",
      "4    The economic turnaround started at the end of ...    half-true   \n",
      "..                                                 ...          ...   \n",
      "328  Over 40 percent of small and mid-size banks th...  barely-true   \n",
      "329  You cant check out a library book without a ph...  barely-true   \n",
      "330  Says that Starbucks took Christmas off of thei...   pants-fire   \n",
      "331  Atmospheric conditions could push a footballs ...  mostly-true   \n",
      "332  Hillary Clinton supports unlimited abortion on...        false   \n",
      "\n",
      "     Predicted_Label                                Probabilities  \n",
      "0                  0   [0.9976226687431335, 0.002377317054197192]  \n",
      "1                  0  [0.9990242719650269, 0.0009757785010151565]  \n",
      "2                  0   [0.9860281944274902, 0.013971861451864243]  \n",
      "3                  0  [0.9967053532600403, 0.0032946544233709574]  \n",
      "4                  0    [0.993440568447113, 0.006559500005096197]  \n",
      "..               ...                                          ...  \n",
      "328                0    [0.7823565006256104, 0.21764346957206726]  \n",
      "329                0   [0.998823344707489, 0.0011766876559704542]  \n",
      "330                0  [0.9994194507598877, 0.0005805320106446743]  \n",
      "331                0   [0.9953773021697998, 0.004622700624167919]  \n",
      "332                0  [0.9980731010437012, 0.0019269217737019062]  \n",
      "\n",
      "[333 rows x 4 columns]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# FINE TUNE ESSA\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
